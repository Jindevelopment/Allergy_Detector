# OCR ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ (ê³ ê¸‰ ì „ì²˜ë¦¬ í¬í•¨)
# ì›¹í˜ì´ì§€ìš© OCR ê¸°ëŠ¥ ì „ë‹´ ëª¨ë“ˆ

import cv2
import pytesseract
import numpy as np
from PIL import Image
import re
import easyocr
import time
import torch

def check_gpu_availability():
    """
    ë§¥ë¶ GPU ê°€ìš©ì„± í™•ì¸ í•¨ìˆ˜
    """
    try:
        # MPS (Metal Performance Shaders) í™•ì¸
        if torch.backends.mps.is_available():
            print("âœ… MPS(Metal Performance Shaders) ì‚¬ìš© ê°€ëŠ¥!")
            return True
        elif torch.cuda.is_available():
            print("âœ… CUDA GPU ì‚¬ìš© ê°€ëŠ¥!")
            return True
        else:
            print("âŒ GPU ì‚¬ìš© ë¶ˆê°€ - CPU ëª¨ë“œë¡œ ì‹¤í–‰")
            return False
    except Exception as e:
        print(f"GPU í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
        return False

def apply_advanced_preprocessing(image):
    """
    ê³ ê¸‰ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜
    """
    # 1ï¸âƒ£ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
    # 2ï¸âƒ£ ë‹¤ì–‘í•œ Blur ë°©ë²•ë“¤ ì ìš©
    # Gaussian Blur
    gaussian_blur = cv2.GaussianBlur(gray, (5, 5), 0)
    
    # Median Blur (ë…¸ì´ì¦ˆ ì œê±°ì— íš¨ê³¼ì )
    median_blur = cv2.medianBlur(gray, 5)
    
    # Bilateral Filter (ì—£ì§€ ë³´ì¡´í•˜ë©´ì„œ ë…¸ì´ì¦ˆ ì œê±°)
    bilateral_blur = cv2.bilateralFilter(gray, 9, 75, 75)
    
    # 3ï¸âƒ£ íˆìŠ¤í† ê·¸ë¨ ê· ë“±í™”
    equalized = cv2.equalizeHist(gray)
    
    # 4ï¸âƒ£ CLAHE (ì ì‘í˜• íˆìŠ¤í† ê·¸ë¨ ê· ë“±í™”)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    clahe_applied = clahe.apply(gray)
    
    # 5ï¸âƒ£ ì±„ë„ ì¡°ì ˆ (Saturation Adjustment)
    # HSV ìƒ‰ìƒ ê³µê°„ìœ¼ë¡œ ë³€í™˜
    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    # ì±„ë„ ì¦ê°€ (1.5ë°°)
    hsv_image[:, :, 1] = np.clip(hsv_image[:, :, 1] * 1.5, 0, 255)
    # ë‹¤ì‹œ BGRë¡œ ë³€í™˜
    saturated_image = cv2.cvtColor(hsv_image, cv2.COLOR_HSV2BGR)
    saturated_gray = cv2.cvtColor(saturated_image, cv2.COLOR_BGR2GRAY)
    
    return {
        'original': gray,
        'gaussian_blur': gaussian_blur,
        'median_blur': median_blur,
        'bilateral_blur': bilateral_blur,
        'equalized': equalized,
        'clahe': clahe_applied,
        'saturated': saturated_gray
    }

def apply_morphology_operations(image):
    """
    ëª¨í´ë¡œì§€ ì—°ì‚° ì ìš© (ì¹¨ì‹, íŒ½ì°½, ë‹«í˜, ì—´ë¦¼)
    """
    # ì»¤ë„ ìƒì„±
    kernel = np.ones((3, 3), np.uint8)
    
    # ì¹¨ì‹ ì—°ì‚° (í…ìŠ¤íŠ¸ë¥¼ ì–‡ê²Œ)
    erosion = cv2.erode(image, kernel, iterations=1)
    
    # íŒ½ì°½ ì—°ì‚° (í…ìŠ¤íŠ¸ë¥¼ ë‘ê»ê²Œ)
    dilation = cv2.dilate(image, kernel, iterations=1)
    
    # ë‹«í˜ ì—°ì‚° (í…ìŠ¤íŠ¸ ë‚´ë¶€ êµ¬ë© ë©”ìš°ê¸°)
    closing = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)
    
    # ì—´ë¦¼ ì—°ì‚° (ì‘ì€ ë…¸ì´ì¦ˆ ì œê±°)
    opening = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)
    
    return {
        'erosion': erosion,
        'dilation': dilation,
        'closing': closing,
        'opening': opening
    }

def apply_multiple_thresholding(image):
    """
    ë‹¤ì–‘í•œ ì´ì§„í™” ë°©ë²• ì ìš©
    """
    # OTSU ì´ì§„í™”
    _, thresh_otsu = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    
    # ì ì‘í˜• ì´ì§„í™” - Gaussian
    thresh_adapt_gaussian = cv2.adaptiveThreshold(
        image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2
    )
    
    # ì ì‘í˜• ì´ì§„í™” - Mean
    thresh_adapt_mean = cv2.adaptiveThreshold(
        image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2
    )
    
    # ì„ê³„ê°’ ì´ì§„í™”
    _, thresh_binary = cv2.threshold(image, 128, 255, cv2.THRESH_BINARY)
    
    return {
        'otsu': thresh_otsu,
        'adapt_gaussian': thresh_adapt_gaussian,
        'adapt_mean': thresh_adapt_mean,
        'binary': thresh_binary
    }

def ocr_image_with_opencv(image, lang="kor+eng", fast_mode=True):
    """
    OpenCV + Tesseract OCR ìµœì í™” í•¨ìˆ˜ (ë‹¤ì–‘í•œ ì „ì²˜ë¦¬ ë°©ë²• ì ìš©)
    image: PIL.Image ë˜ëŠ” íŒŒì¼ ê²½ë¡œ
    lang: OCR ì–¸ì–´ ì„¤ì •
    fast_mode: ë¹ ë¥¸ ëª¨ë“œ (ê¸°ë³¸ê°’: True)
    """
    # ì´ë¯¸ì§€ê°€ PIL ê°ì²´ë¼ë©´ OpenCV í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    if isinstance(image, Image.Image):
        image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
    elif isinstance(image, str):  # íŒŒì¼ ê²½ë¡œì¼ ê²½ìš°
        image = cv2.imread(image)
        if image is None:
            raise FileNotFoundError(f"ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image}")

    # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • (ì ë‹¹í•œ í¬ê¸°ë¡œ)
    height, width = image.shape[:2]
    if width > 1200 or height > 1200:
        scale = min(1200/width, 1200/height)
        new_width = int(width * scale)
        new_height = int(height * scale)
        image = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_AREA)

    if fast_mode:
        # ğŸš€ ë¹ ë¥¸ ëª¨ë“œ: ê¸°ë³¸ ì „ì²˜ë¦¬ë§Œ
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        gray = cv2.equalizeHist(gray)
        blurred = cv2.GaussianBlur(gray, (3, 3), 0)
        _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        config = "--psm 3 --oem 3 -c preserve_interword_spaces=1"
        
    else:
        # ğŸ¯ ì •ë°€ ëª¨ë“œ: ë‹¤ì–‘í•œ ì „ì²˜ë¦¬ ë°©ë²• ì‹œë„
        # ê³ ê¸‰ ì „ì²˜ë¦¬ ì ìš©
        processed_images = apply_advanced_preprocessing(image)
        
        # ê°€ì¥ íš¨ê³¼ì ì¸ ì´ë¯¸ì§€ ì„ íƒ (CLAHE ì ìš©ëœ ì´ë¯¸ì§€)
        best_image = processed_images['clahe']
        
        # ëª¨í´ë¡œì§€ ì—°ì‚° ì ìš©
        morph_images = apply_morphology_operations(best_image)
        
        # ê°€ì¥ íš¨ê³¼ì ì¸ ëª¨í´ë¡œì§€ ê²°ê³¼ ì„ íƒ (ë‹«í˜ ì—°ì‚°)
        best_morph = morph_images['closing']
        
        # ë‹¤ì–‘í•œ ì´ì§„í™” ë°©ë²• ì ìš©
        thresh_images = apply_multiple_thresholding(best_morph)
        
        # ê°€ì¥ íš¨ê³¼ì ì¸ ì´ì§„í™” ê²°ê³¼ ì„ íƒ (ì ì‘í˜• Gaussian)
        thresh = thresh_images['adapt_gaussian']
        
        # ì¶”ê°€ ëª¨í´ë¡œì§€ ì—°ì‚°ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì˜ì—­ ê°•í™”
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
        thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)
        
        config = "--psm 6 --oem 3 -c preserve_interword_spaces=1 -c tessedit_char_whitelist=0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyzê°€-í£():.,()[]{}"

    # OCR ìˆ˜í–‰ (í•œêµ­ì–´ ìš°ì„ )
    text = pytesseract.image_to_string(thresh, lang=lang, config=config)
    return text.strip()

def ocr_with_easyocr(image_path_or_object, lang=['ko', 'en']):
    """
    EasyOCRì„ ì‚¬ìš©í•œ ê³ ì„±ëŠ¥ OCR í•¨ìˆ˜ (í•œêµ­ì–´ íŠ¹í™” - ë§¥ë¶ GPU ì§€ì›)
    """
    try:
        # ë§¥ë¶ M1/M2/M3 ì¹©ì—ì„œ MPS(Metal Performance Shaders) ì‚¬ìš©
        if torch.backends.mps.is_available():
            print("ğŸš€ ë§¥ë¶ GPU(MPS) ê°€ì† ì‚¬ìš© ì¤‘...")
            reader = easyocr.Reader(lang, gpu=True)  # MPS ì‚¬ìš©
        else:
            print("ğŸ’» CPU ëª¨ë“œë¡œ ì‹¤í–‰ ì¤‘...")
            reader = easyocr.Reader(lang, gpu=False)
        
        # ì´ë¯¸ì§€ ì½ê¸°
        if isinstance(image_path_or_object, str):
            image = cv2.imread(image_path_or_object)
        else:
            # PIL Imageë¥¼ numpy arrayë¡œ ë³€í™˜
            image = np.array(image_path_or_object)
            if len(image.shape) == 3 and image.shape[2] == 3:
                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
        
        # EasyOCRë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        results = reader.readtext(image)
        
        # ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        extracted_text = ""
        for (bbox, text, confidence) in results:
            if confidence > 0.5:  # ì‹ ë¢°ë„ 50% ì´ìƒë§Œ ì‚¬ìš©
                extracted_text += text + " "
        
        return extracted_text.strip()
    
    except Exception as e:
        print(f"EasyOCR ì˜¤ë¥˜: {e}")
        return ""

def ocr_with_enhanced_preprocessing(image_path_or_object, use_easyocr=True):
    """
    í–¥ìƒëœ ì „ì²˜ë¦¬ + ê³ ì„±ëŠ¥ OCR í•¨ìˆ˜ (ì›¹í˜ì´ì§€ìš©)
    """
    try:
        # ì´ë¯¸ì§€ ì½ê¸°
        if isinstance(image_path_or_object, str):
            image = cv2.imread(image_path_or_object)
        else:
            image = np.array(image_path_or_object)
            if len(image.shape) == 3 and image.shape[2] == 3:
                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
        
        if image is None:
            return ""
        
        # ê³ ê¸‰ ì „ì²˜ë¦¬ ì ìš©
        processed_images = apply_advanced_preprocessing(image)
        
        # ì—¬ëŸ¬ ì „ì²˜ë¦¬ ê²°ê³¼ ì¤‘ ê°€ì¥ ì¢‹ì€ ê²ƒë“¤ ì‹œë„
        best_images = [
            processed_images['clahe'],  # CLAHE ì ìš©
            processed_images['equalized'],  # íˆìŠ¤í† ê·¸ë¨ ê· ë“±í™”
            processed_images['bilateral_blur'],  # Bilateral Filter
            processed_images['original']  # ì›ë³¸
        ]
        
        all_texts = []
        
        if use_easyocr:
            # EasyOCR ì‚¬ìš© (ë§¥ë¶ GPU ì§€ì›)
            try:
                if torch.backends.mps.is_available():
                    reader = easyocr.Reader(['ko', 'en'], gpu=True)
                else:
                    reader = easyocr.Reader(['ko', 'en'], gpu=False)
                
                for img in best_images:
                    try:
                        results = reader.readtext(img)
                        text = ""
                        for (bbox, detected_text, confidence) in results:
                            if confidence > 0.3:  # ë‚®ì€ ì„ê³„ê°’ìœ¼ë¡œ ë” ë§ì€ í…ìŠ¤íŠ¸ ìº¡ì²˜
                                text += detected_text + " "
                        if text.strip():
                            all_texts.append(text.strip())
                    except:
                        continue
            except Exception as e:
                print(f"EasyOCR ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                use_easyocr = False
        
        if not use_easyocr:
            # Tesseract ì‚¬ìš©
            for img in best_images:
                try:
                    # ëª¨í´ë¡œì§€ ì—°ì‚° ì ìš©
                    morph_images = apply_morphology_operations(img)
                    best_morph = morph_images['closing']
                    
                    # ì´ì§„í™”
                    thresh_images = apply_multiple_thresholding(best_morph)
                    thresh = thresh_images['adapt_gaussian']
                    
                    # OCR ìˆ˜í–‰
                    text = pytesseract.image_to_string(thresh, lang='kor+eng', config='--psm 6 --oem 3')
                    if text.strip():
                        all_texts.append(text.strip())
                except:
                    continue
        
        # ëª¨ë“  ê²°ê³¼ë¥¼ í•©ì¹˜ê³  ì¤‘ë³µ ì œê±°
        combined_text = " ".join(all_texts)
        return combined_text.strip()
    
    except Exception as e:
        print(f"í–¥ìƒëœ OCR ì˜¤ë¥˜: {e}")
        return ""

def extract_text_from_image(image_path_or_object, use_easyocr=True, fast_mode=False):
    """
    ì›¹í˜ì´ì§€ìš© ë©”ì¸ OCR í•¨ìˆ˜
    """
    try:
        start_time = time.time()
        
        if use_easyocr:
            # ğŸš€ EasyOCR ì‚¬ìš© (ê³ ì„±ëŠ¥)
            extracted_text = ocr_with_enhanced_preprocessing(image_path_or_object, use_easyocr=True)
            engine_name = "EasyOCR"
        else:
            # ğŸ“œ Tesseract ì‚¬ìš© (ê¸°ì¡´)
            extracted_text = ocr_image_with_opencv(image_path_or_object, "kor+eng", fast_mode)
            engine_name = "Tesseract"
        
        end_time = time.time()
        processing_time = round(end_time - start_time, 2)
        
        return {
            'text': extracted_text,
            'processing_time': processing_time,
            'engine': engine_name,
            'mode': 'fast' if fast_mode else 'precise',
            'success': True
        }
    except Exception as e:
        return {
            'text': '',
            'processing_time': 0,
            'engine': 'Error',
            'mode': 'fast' if fast_mode else 'precise',
            'success': False,
            'error': str(e)
        }

# ì›¹í˜ì´ì§€ì—ì„œ ì‚¬ìš©í•  ê°„ë‹¨í•œ OCR í•¨ìˆ˜ (í˜¸í™˜ì„± ìœ ì§€)
def simple_ocr(image, lang="kor+eng"):
    """
    ê°„ë‹¨í•œ OCR í•¨ìˆ˜ (ê¸°ì¡´ ì›¹í˜ì´ì§€ ì½”ë“œì™€ì˜ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€)
    """
    try:
        result = extract_text_from_image(image, use_easyocr=True, fast_mode=True)
        return result['text']
    except:
        # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ OCR ë°©ì‹ ì‚¬ìš©
        return ocr_image_with_opencv(image, lang, fast_mode=True)